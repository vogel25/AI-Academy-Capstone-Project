{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gitpython\n",
    "!pip install keras==2.3.1\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import LSTM\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "import os\n",
    "import json\n",
    "import sklearn\n",
    "import sys\n",
    "import pickle\n",
    "import re\n",
    "import requests\n",
    "import git\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('fivethirtyeight')\n",
    "import statsmodels.api as sm\n",
    "import matplotlib\n",
    "matplotlib.rcParams['axes.labelsize'] = 14\n",
    "matplotlib.rcParams['xtick.labelsize'] = 12\n",
    "matplotlib.rcParams['ytick.labelsize'] = 12\n",
    "matplotlib.rcParams['text.color'] = 'k'\n",
    "import plotly.offline as pyoff\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.feature_extraction import text\n",
    "from string import punctuation, printable\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_json = './ai-workflow-capstone/cs-train'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "json_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_data = []\n",
    "for i in json_files:\n",
    "    data = pd.read_json(path_to_json+'/'+i)\n",
    "    data = data.rename(columns={'ID_STREAM': 'stream_id', 'VIEWED_TIMES': 'times_viewed', 'price' : 'total_price'})\n",
    "    appended_data.append(data)\n",
    "appended_data = pd.concat(appended_data)\n",
    "appended_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_data[\"date\"] = appended_data[\"day\"].astype(str) + '-' + appended_data[\"month\"].astype(str) + '-' + appended_data[\"year\"].astype(str)\n",
    "appended_data['invoice'] = appended_data['invoice'].str.replace(r'\\D', '').astype(int)\n",
    "appended_data['date']= pd.to_datetime(appended_data['date'])\n",
    "appended_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"unique values stream_id =\",  appended_data['stream_id'].nunique())\n",
    "print(\"unique values country =\",  appended_data['country'].nunique())\n",
    "print(\"unique values customer_id =\",  appended_data['customer_id'].nunique())\n",
    "print(\"uinique values invoice =\",  appended_data['invoice'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top10countries = appended_data.groupby(by=[\"country\"]).sum()\n",
    "Top10countries = Top10countries.sort_values(by=['total_price'], ascending=False)\n",
    "Top10countries = Top10countries.drop(columns=['customer_id', 'invoice', 'year', 'month', 'day'])\n",
    "Top10countries.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "notintop10 = Top10countries.index.values.tolist()\n",
    "del notintop10[:n]\n",
    "print(notintop10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_data_top10 = appended_data\n",
    "for c in notintop10:\n",
    "    indexNames = appended_data_top10[(appended_data_top10['country'] == c)].index\n",
    "    appended_data_top10.drop(indexNames , inplace=True)\n",
    "appended_data_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"unique values stream_id =\",  appended_data['stream_id'].nunique())\n",
    "print(\"unique values country =\",  appended_data['country'].nunique())\n",
    "print(\"unique values customer_id =\",  appended_data['customer_id'].nunique())\n",
    "print(\"unique values invoice =\",  appended_data['invoice'].nunique())\n",
    "\n",
    "appended_data.country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = appended_data_top10.groupby(by=['country', 'date', 'year', 'month', 'day']).sum()\n",
    "grouped_data = grouped_data.drop(columns=['invoice', 'customer_id'])\n",
    "grouped_data.reset_index(inplace=True)\n",
    "grouped_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in grouped_data['country'].unique():\n",
    "     grouped_data[grouped_data['country']==country].sort_values('date').plot.line(x='date',\n",
    "                                                              y='total_price',\n",
    "                                                              title=country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = grouped_data.groupby(grouped_data.country) \n",
    "df_UK = grouped.get_group(\"United Kingdom\") \n",
    "df_EIRE = grouped.get_group(\"EIRE\")\n",
    "df_Germany = grouped.get_group(\"Germany\")\n",
    "df_France = grouped.get_group(\"France\")\n",
    "df_Spain = grouped.get_group(\"Spain\")\n",
    "df_NL = grouped.get_group(\"Netherlands\")\n",
    "df_Portugal = grouped.get_group(\"Portugal\")\n",
    "df_Norway = grouped.get_group(\"Norway\")\n",
    "df_HK = grouped.get_group(\"Hong Kong\")\n",
    "df_Singh = grouped.get_group(\"Singapore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UK[\"yearmonth\"] = df_UK[\"month\"].astype(str) + '-' + df_UK[\"year\"].astype(str)\n",
    "df_UK['yearmonth']= pd.to_datetime(df_UK['yearmonth'])\n",
    "df_UK = df_UK.groupby(by=[\"yearmonth\"]).sum()\n",
    "\n",
    "df_EIRE[\"yearmonth\"] = df_EIRE[\"month\"].astype(str) + '-' + df_EIRE[\"year\"].astype(str)\n",
    "df_EIRE['yearmonth']= pd.to_datetime(df_EIRE['yearmonth'])\n",
    "df_EIRE = df_EIRE.groupby(by=[\"yearmonth\"]).sum()\n",
    "\n",
    "df_Germany[\"yearmonth\"] = df_Germany[\"month\"].astype(str) + '-' + df_Germany[\"year\"].astype(str)\n",
    "df_Germany['yearmonth']= pd.to_datetime(df_Germany['yearmonth'])\n",
    "df_Germany = df_Germany.groupby(by=[\"yearmonth\"]).sum()\n",
    "\n",
    "df_France[\"yearmonth\"] = df_France[\"month\"].astype(str) + '-' + df_France[\"year\"].astype(str)\n",
    "df_France['yearmonth']= pd.to_datetime(df_France['yearmonth'])\n",
    "df_France = df_France.groupby(by=[\"yearmonth\"]).sum()\n",
    "\n",
    "df_Spain[\"yearmonth\"] = df_Spain[\"month\"].astype(str) + '-' + df_Spain[\"year\"].astype(str)\n",
    "df_Spain['yearmonth']= pd.to_datetime(df_Spain['yearmonth'])\n",
    "df_Spain = df_Spain.groupby(by=[\"yearmonth\"]).sum()\n",
    "\n",
    "df_NL[\"yearmonth\"] = df_NL[\"month\"].astype(str) + '-' + df_NL[\"year\"].astype(str)\n",
    "df_NL['yearmonth']= pd.to_datetime(df_NL['yearmonth'])\n",
    "df_NL = df_NL.groupby(by=[\"yearmonth\"]).sum()\n",
    "\n",
    "df_Portugal[\"yearmonth\"] = df_Portugal[\"month\"].astype(str) + '-' + df_Portugal[\"year\"].astype(str)\n",
    "df_Portugal['yearmonth']= pd.to_datetime(df_Portugal['yearmonth'])\n",
    "df_Portugal = df_Portugal.groupby(by=[\"yearmonth\"]).sum()\n",
    "\n",
    "df_Norway[\"yearmonth\"] = df_Norway[\"month\"].astype(str) + '-' + df_Norway[\"year\"].astype(str)\n",
    "df_Norway['yearmonth']= pd.to_datetime(df_Norway['yearmonth'])\n",
    "df_Norway = df_Norway.groupby(by=[\"yearmonth\"]).sum()\n",
    "\n",
    "df_HK[\"yearmonth\"] = df_HK[\"month\"].astype(str) + '-' + df_HK[\"year\"].astype(str)\n",
    "df_HK['yearmonth']= pd.to_datetime(df_HK['yearmonth'])\n",
    "df_HK = df_HK.groupby(by=[\"yearmonth\"]).sum()\n",
    "\n",
    "df_Singh[\"yearmonth\"] = df_Singh[\"month\"].astype(str) + '-' + df_Singh[\"year\"].astype(str)\n",
    "df_Singh['yearmonth']= pd.to_datetime(df_Singh['yearmonth'])\n",
    "df_Singh = df_Singh.groupby(by=[\"yearmonth\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UK.reset_index(inplace=True)\n",
    "df_UK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UK = df_UK.set_index('yearmonth')\n",
    "df_UK.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UK.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_UK['total_price'].resample('MS').mean()\n",
    "y['2017':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.plot(figsize=(15, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_datax = pd.get_dummies(grouped_data, columns=['country'], drop_first=True, prefix='country')\n",
    "date_time = pd.to_datetime(grouped_datax.pop('date'), format='%d.%m.%Y %H:%M:%S')\n",
    "plot_cols = ['total_price', 'times_viewed']\n",
    "plot_features = grouped_datax[plot_cols]\n",
    "plot_features.index = date_time\n",
    "_ = plot_features.plot(subplots=True)\n",
    "\n",
    "plot_features = grouped_datax[plot_cols][:480]\n",
    "plot_features.index = date_time[:480]\n",
    "_ = plot_features.plot(subplots=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_indices = {name: i for i, name in enumerate(grouped_datax.columns)}\n",
    "\n",
    "n = len(grouped_datax)\n",
    "train_df = grouped_datax[0:int(n*0.7)]\n",
    "val_df = grouped_datax[int(n*0.7):int(n*0.9)]\n",
    "test_df = grouped_datax[int(n*0.9):]\n",
    "\n",
    "num_features = grouped_datax.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "train_df = (train_df - train_mean) / train_std\n",
    "val_df = (val_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df_std = (grouped_datax - train_mean) / train_std\n",
    "df_std = df_std.melt(var_name='Column', value_name='Normalized')\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n",
    "_ = ax.set_xticklabels(grouped_datax.keys(), rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grouped_datax.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_target = grouped_datax['total_price']\n",
    "dataset_data = grouped_datax\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset_data, dataset_target, test_size=0.2,  random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UK = df_UK.drop(columns=['year', 'month', 'day'])\n",
    "df_UK.reset_index(inplace=True)\n",
    "df_diff_UK = df_UK.copy()\n",
    "df_diff_UK['prev_sales'] = df_diff_UK['total_price'].shift(1)\n",
    "#drop the null values and calculate the difference\n",
    "df_diff_UK = df_diff_UK.dropna()\n",
    "df_diff_UK['diff'] = (df_diff_UK['total_price'] - df_diff_UK['prev_sales'])\n",
    "#create dataframe for transformation from time series to supervised\n",
    "df_supervised_UK = df_diff_UK.drop(['prev_sales'],axis=1)\n",
    "#adding lags\n",
    "for inc in range(1,13):\n",
    "    field_name = 'lag_' + str(inc)\n",
    "    df_supervised_UK[field_name] = df_supervised_UK['diff'].shift(inc)\n",
    "#drop null values\n",
    "df_supervised_UK = df_supervised_UK.dropna().reset_index(drop=True)\n",
    "\n",
    "# Import statsmodels.formula.api\n",
    "import statsmodels.formula.api as smf\n",
    "# Define the regression formula\n",
    "model = smf.ols(formula='diff ~ lag_1 + lag_2 + lag_3 + lag_4 + lag_5 + lag_6', data=df_supervised)\n",
    "# Fit the regression\n",
    "model_fit = model.fit()\n",
    "# Extract the adjusted r-squared\n",
    "regression_adj_rsq = model_fit.rsquared_adj\n",
    "df_supervised.drop(columns=['lag_7', 'lag_8', 'lag_9', 'lag_10', 'lag_11', 'lag_12'])\n",
    "print(regression_adj_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import MinMaxScaler and create a new dataframe for LSTM model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "df_model = df_supervised.drop(['total_price','yearmonth'],axis=1)\n",
    "#split train and test set\n",
    "train_set, test_set = df_model[0:-6].values, df_model[-6:].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply Min Max Scaler\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler = scaler.fit(train_set)\n",
    "# reshape training set\n",
    "train_set = train_set.reshape(train_set.shape[0], train_set.shape[1])\n",
    "train_set_scaled = scaler.transform(train_set)\n",
    "# reshape test set\n",
    "test_set = test_set.reshape(test_set.shape[0], test_set.shape[1])\n",
    "test_set_scaled = scaler.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_set_scaled[:, 1:], train_set_scaled[:, 0:1]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test, y_test = test_set_scaled[:, 1:], test_set_scaled[:, 0:1]\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(4, batch_input_shape=(1, X_train.shape[1], X_train.shape[2]), stateful=True))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, nb_epoch=100, batch_size=1, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test,batch_size=1)\n",
    "#for multistep prediction, you need to replace X_test values with the predictions coming from t-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape y_pred\n",
    "y_pred = y_pred.reshape(y_pred.shape[0], 1, y_pred.shape[1])\n",
    "#rebuild test set for inverse transform\n",
    "pred_test_set = []\n",
    "for index in range(0,len(y_pred)):\n",
    "    print(np.concatenate([y_pred[index],X_test[index]],axis=1))\n",
    "    pred_test_set.append(np.concatenate([y_pred[index],X_test[index]],axis=1))\n",
    "#reshape pred_test_set\n",
    "pred_test_set = np.array(pred_test_set)\n",
    "pred_test_set = pred_test_set.reshape(pred_test_set.shape[0], pred_test_set.shape[2])\n",
    "#inverse transform\n",
    "pred_test_set_inverted = scaler.inverse_transform(pred_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe that shows the predicted sales\n",
    "result_list = []\n",
    "sales_dates = list(df_UK[-7:].yearmonth)\n",
    "act_sales = list(df_UK[-7:].total_price)\n",
    "for index in range(0,len(pred_test_set_inverted)):\n",
    "    result_dict = {}\n",
    "    result_dict['pred_value'] = int(pred_test_set_inverted[index][0] + act_sales[index])\n",
    "    result_dict['yearmonth'] = sales_dates[index+1]\n",
    "    result_list.append(result_dict)\n",
    "df_result = pd.DataFrame(result_list)\n",
    "#for multistep prediction, replace act_sales with the predicted sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with actual sales dataframe\n",
    "df_sales_pred = pd.merge(df_UK,df_result,on='yearmonth',how='left')\n",
    "#plot actual and predicted\n",
    "plot_data = [\n",
    "    go.Scatter(\n",
    "        x=df_sales_pred['yearmonth'],\n",
    "        y=df_sales_pred['total_price'],\n",
    "        name='actual'\n",
    "    ),\n",
    "        go.Scatter(\n",
    "        x=df_sales_pred['yearmonth'],\n",
    "        y=df_sales_pred['pred_value'],\n",
    "        name='predicted'\n",
    "    )\n",
    "    \n",
    "]\n",
    "plot_layout = go.Layout(\n",
    "        title='Sales Prediction'\n",
    "    )\n",
    "fig = go.Figure(data=plot_data, layout=plot_layout)\n",
    "pyoff.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
